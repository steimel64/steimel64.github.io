{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginner tutorial for building basic Convolutional Neural Network by Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you want to start a project related to neural networks and arent sure where to begin?  I can also tell you honestly this is how I was also feeling when I saw all the crazy diagrams, formulas, and heard terms like the sigmoid function.\n",
    "\n",
    "Have no fear as this tutorial is geared towards complete beginners and will cover the basic intuition required to understand CNNs as well as their practical application in Python/Jupyter Notebooks. This will be done through applying the CNN (Convolutional Neural Network) on the popular MNIST dataset. \n",
    "\n",
    "Covered in this tutorial will be: \n",
    "* An overview on the constantly growing area of Computer Vision. \n",
    "* What is the MNIST dataset? \n",
    "* What are Neural Networks and Convolutional Neural Networks \n",
    "* An overview on Keras \n",
    "* Sample python code to implement a CNN model in Jupyter Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Computer Vision Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether you look at autonomous vehicles being developed by Tesla/Toyota, facial recognition software on our smart phones, or even image recognition applications- Computer Vision is increasingly being valued and sought after by all businesses/organizations. There is no doubting the competitive advantage brought to businesses that adapt machine learning as well as the economic impact it has on a companies bottom line. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tesla](https://electrek.files.wordpress.com/2016/11/tesla-vision-self-driving-video.png?w=1600&h=1000)\n",
    "Source: Tesla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to techopedia, \"Computer Vision can be defined as the field of computer science that works on enabling computers to see, identify, and process images in the same way that a human does.\" As seen below- Computers view images in a much different way than the way humans do. To say it simply, What looks like a dog in the human eye on the left picture is just a 28x28 matrix that indicate pixels at a specific area in an image for computers. However, when applying the 28x28 matrix of pixels into a deep learning model like a convolutional neural network, it becomes very easy for a computer to process an image in a human like fashion through feature extraction and pattern recognition. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Corgi](https://adeshpande3.github.io/assets/Corgi3.png)\n",
    "Screenshot Source: https://adeshpande3.github.io/assets/Corgi3.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample computer vision problem application may be an image classification problem which aims to classify an image as either a cat or dog. This is done by creating a (CNN) Convolutional Neural Network to process the image pixel data and generating a model that will output the probability an image is a dog or cat. Simply put, a basic neural network may classify an image as dog if it had a 51 % probability or more of being a dog.\n",
    "\n",
    "A hilarious application in modern American media is an app called Not Hot Dog from the popular show Silicon Valley.  The application is known as ホットドッグを見分けるアプリ In Japanese and was introduced on the show as a joke but also illustrates the true power of Image Classification Applications that are given alot of data and a machine learning algorithm.\n",
    "\n",
    "![Hot Dog](http://cdn.strategyonline.ca/wp/wp-content/uploads/2017/05/nothotdog-622x405.jpg?cb9474)\n",
    "Source: iTunes\n",
    " \n",
    " Incase you are interested in reading more about this application/show:\n",
    "https://forbesjapan.com/articles/detail/16307"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A current Machine Learning Problem trending on deeplearninganalytics.jp (a famous machine learning competition site on in Japan) is a receipt reading engine (レシート読み取りエンジン作成チャレンジコンテスト where the goal is to develop a computer vision application that can read various parts of a receipt. The current prize money for this contest is  120万円 for first prize, 60万円 for second prize, and 30万円 for third prize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ReceiptChallenge](https://i.deepanalytics.jp/i/wh0t4i5072)\n",
    "Source: https://i.deepanalytics.jp/i/wh0t4i5072"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The competition can be found at the link below and hundreds of developers/machine learning engineers around Japan will likely take part in it. If you would like to compete maybe after this tutorial give it a try and read how others approach the problem! \n",
    "\n",
    "https://deepanalytics.jp/compe/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example though truly illustrates the value companies place on those who can develop these types of technologies. Why not be a part of the cutting edge computer vision revolution and begin with this tutorial?\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. What is the MNIST Dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before beginning the coding aspects of the project we will first cover the history of the MNIST dataset and its application to computer vision research. MNIST is a database often used for image classification problems that contains 60,000 handwritten digits from 1-9. In simple terms, the goal of the dataset is to classify a handwritten image as its correct label or number which we will cover later in this tutorial. An example of the handwritten images can be found below. Many people say that MNIST is the hello world of machine learning and it is also often used to benchmark the performance of ML algorithms. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MNIST1](http://corochann.com/wp-content/uploads/2017/02/mnist_plot-800x600.png)\n",
    "Source: http://corochann.com/wp-content/uploads/2017/02/mnist_plot-800x600.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the image classification sense it is considered a supervised learning problem. Supervised learning means the correct classes or labels are known in the training data. Training data is the data used to train the algorithm while the test data is used to validate the model results. Usually when working on ML problems it is very common to split the data into 80 % Training Data and 20 % Test/Validation Data.\n",
    "\n",
    "As we can see in the above picture, each associated hand drawn number has a label associated with each observation. This helps with the model training so that it generalizes based on features what number a number is on an unseen observation. Its key to note that the main goal of machine learning and pattern recognition is to predict based on features given and patterns derived through those features. \n",
    "\n",
    "If we look at a comparison between Supervised learning and Unsupervised learning we can see that a supervised learning model already has access to the data to tell the difference between and O and an X. The Unsupervised Learning Model does not know this and has to learn based on something like clustering or similarity measures. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SupervisedLearning](https://lakshaysuri.files.wordpress.com/2017/03/sup-vs-unsup.png?w=660)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images Represented as matrixes: \n",
    "\n",
    "When working in machine learning many people will probably think of the word data. Data is extremely important for all machine learning models. But how is an image represented in data format you may ask? I also had some doubts or concerns when I first had to approach these types of problems as I was used to traditional table data in excel. \n",
    "\n",
    "When working with images, they are usually represented as height x width x channels in matrix format. Images can either have 1 channel or 3 channels. 3 channel would represent the dimensions of Red, Green, Blue or the RGB color. 1 channel would indicate that the image is a grayscale which is the type of problem the MNIST dataset handles. Pixels range in values from 0-255. An example of this can be seen below:\n",
    "\n",
    "\n",
    "![Test](https://ujwlkarn.files.wordpress.com/2016/08/8-gif.gif?w=192&h=192&zoom=2)\n",
    "Source: https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is an example of an image with 1 channels or gray scale. The below represents a colored image by dimensions of height (32) x width (32) x channels (3). As you can see this makes the object become 3d. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![3dFig](https://cdn-images-1.medium.com/max/1600/1*C55kkMQHSE1x9p2LdMf-DQ.png)\n",
    "Source: https://cdn-images-1.medium.com/max/1600/1*C55kkMQHSE1x9p2LdMf-DQ.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. What are Neural Networks and Convolutional Neural Networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first question many of you might have is what are neural networks and deep learning let alone what are CNN's (Convolutional Neural Networks). Neural Networks are Computer Systems that are structured and function similar to the human brain. An interesting infographic of the many different types of Neural Networks compiled by Fjodor van Veen from Asimov institute can be found below. It's amazing to see all the various types of neural networks in existence. \n",
    "\n",
    "![NN](https://cdn-images-1.medium.com/max/2000/1*cuTSPlTq0a_327iTPJyD-Q.png)\n",
    "\n",
    "In summary, CNN's are a category of neural networks which perform extremely well in image recognition and classification. \n",
    "\n",
    "The First CNN was called LeNet which was created in the 90s. They have only recently been growing in popularity but they have since exploded after the recent paper on Alexnet which received a top five error rate of 15.3 % in comparison to the 2nd model at 26.2 % which was considered state of the art at the time. \n",
    "\n",
    "More can be read about the feat at the research paper that was published in 2012: \n",
    "https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\n",
    "\n",
    "CNN's require a few complex processes and layers which will be briefly explained but not too much into detail. Just as a disclaimer this will be explained at a level for most beginners.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Convolution \n",
    "\n",
    "Convolution is a process used to extract features from an input image. There are two inputs in this process which are the image in matrix format as well as the filter/kernel. In the below example we have an image that is 5x5 (green) with a filter and kernel that is 3x3 (orange). The dot product (a linear algebra operation) is then calculated at each segment to create the Convolved Feature/Feature Map. The output of this operation on an image can be seen more in depth with the below building picture. \n",
    "\n",
    "![Conv1](http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif)\n",
    "Source: http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution\n",
    "\n",
    "![Conv1](https://ujwlkarn.files.wordpress.com/2016/08/giphy.gif?w=480&zoom=2)\n",
    "Source: https://cs.nyu.edu/~fergus/tutorials/deep_learning_cvpr12/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Linearity-Relu \n",
    "\n",
    "Relu is an activation function that helps add non-linearity to the neural network. Other functions that can be used also include the sigmoid and hyperbolic tangent but it has been shown that relu has increased performance. After relu is inputted into a feature map a rectified feature map is created. This is illustrated below: \n",
    "\n",
    "![Relu](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-07-at-6-18-19-pm.png?w=1496)\n",
    "Source: https://cs.nyu.edu/~fergus/tutorials/deep_learning_cvpr12/\n",
    "\n",
    "\n",
    "More Activation Functions and their shapes! Not important to memorize as a beginner but interesting to take a look at. \n",
    "\n",
    "![Relu2](https://cdn-images-1.medium.com/max/1600/1*p_hyqAtyI8pbt2kEl6siOQ.png)\n",
    "Source: https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Pooling or Sub Sampling \n",
    "\n",
    "The Pooling or Sub-Sampling step then takes the rectified feature map and uses a max, sum, or average function over our defined patch size.  The example below takes the max of the number in a 2x2 space in the rectified feature map. \n",
    "\n",
    "![Conv1](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-10-at-3-38-39-am.png?w=988![image.png](attachment:image.png)\n",
    "Source: http://cs231n.github.io/convolutional-networks/\n",
    "\n",
    "The effect of this operation on a max pool/sum pool can be seen below. \n",
    "\n",
    "![Conv2](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-07-at-6-11-53-pm.png)\n",
    "Source: https://cs.nyu.edu/~fergus/tutorials/deep_learning_cvpr12/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification (Fully Connected Layer)\n",
    "\n",
    "Convolution, Relu, and Pooling are all vital to CNN architecture and function in conjunction to extract features to help produce a classification result. The softmax function is then used to generate the probability that a number belongs to a certain class (totalling 1 for all classes). In our case, with the MNIST dataset the softmax function would give us a probability for each value totalling 1 when summed up. The highest probability would be our classification result as seen below: This entire process can be seen below with an example that classifies a bird as either dog, sunset, bird, or cat. \n",
    "\n",
    "![Conv3](https://adeshpande3.github.io/assets/Cover.png)\n",
    "Source: https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/\n",
    " \n",
    "If this section is too complex for you no worries but in summary a neural network is a complex architecture used to convert an Image to Feature Map to Rectified Feature Map to a Fully connected network for final classification. For this project our goal would be to convert an MNIST image into a machine generated classification or number. \n",
    "\n",
    "You can also supplement your understanding of this process by playing with the visualization attached which works with the MNIST dataset and illustrates the layering process. \n",
    "\n",
    "http://scs.ryerson.ca/~aharley/vis/conv/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. What is Keras? Guide to setup/Why Keras? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Keras](https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be wondering what is Keras and why does it sound so cool ?! Keras is a Python Deep Learning Library which is self described as \"a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation.\" Keras also eases the neural network building process and is used by many technology giants like Google, Microsoft, Nvidia, and AWS. \n",
    "\n",
    "More details can be found at the below link as well as reference documentation. Today we will be utilizing Keras to create a Convolutional Neural Network in conjuction with the MNIST dataset.  \n",
    "\n",
    "https://keras.io/\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Python Coding Tutorial\n",
    "\n",
    "This guide will now begin the coding tutorial! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps Outlined in this Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Install/Data Exploration/Data Cleaning/Keras CNN \n",
    "\n",
    "* Step 1: Install essential Keras Packages/Anaconda\n",
    "* Step 2: Step Environment as theano  \n",
    "* Step 3: Import Essential Packages needed to run this tutorial \n",
    "* Step 4: Import MNIST dataset \n",
    "* Step 5: Split Data into X(features) and y(target/labels) \n",
    "* Step 6: Explore the Data \n",
    "* Step 7: Split features into 28x28 matrix\n",
    "* Step 8: Visualize the data in matplotlib \n",
    "* Step 9: Confirm our hypothesis \n",
    "* Step 10: Data Pre-processing for Neural Networks \n",
    "* Step 11: Build the Model \n",
    "* Step 12: Build the Model Layers\n",
    "* Step 13: Configure the Learning Process \n",
    "* Step 14: Fit the model to the data \n",
    "* Step 15: Evaluate the Model\n",
    "* Step 16: View the predictions vs actual values (optional)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Essential Keras Library/Anaconda\n",
    "As a machine learning beginner, you will see that you need to install all packages for software before you can use them in a live python environment.\n",
    "\n",
    "If you are completely new to python I would first recommend the anaconda package which is a popular package for python data science tools. Instructions on how to download it can be found at the below link. \n",
    "\n",
    "![Anaconda](https://upload.wikimedia.org/wikipedia/en/c/cd/Anaconda_Logo.png)\n",
    "\n",
    "https://anaconda.org/anaconda/python\n",
    "\n",
    "Keras installation instructions can be found at the below link. \n",
    "\n",
    "https://keras.io/#installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setup Environment as theano \n",
    "\n",
    "The first step will be to setup the Keras environment to use theano in the backend. I wont go into detail on what this means but essentially they are a few  two popular backends you may of heard of called theano and tensorflow that Keras can run on. This tutorial will utilize the theano backend. For more details on what this means please reference the associated link. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "import keras as ks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Import Essential Packages needed to run this tutorial\n",
    "Next, we will import the required packages needed for this project including the Keras Convolutional Neural Network, sklearn, pandas, and matplotlib. These should all be included with the original Anaconda and Keras install. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Import MNIST Dataset \n",
    "For the purposes of this tutorial we will be importing the MNIST dataset from the sklearn package. The below code downloads the MNIST data into the mnist variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Split Data Into X(Features) y(Target)\n",
    "\n",
    "The next step is to split the mnist table into the features and target arrays. In Machine Learning, the goal is often to predict a Target(y) through input features(X). As this is a supervised learning problem all of the data already has its target feature in place for validating the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Lets Explore the data! \n",
    "When we explore the shape of X we can see that there are 70000 rows and 784 features. If we multiply 28 x 28 we can see that this also equals 784. In summary, the shape of the array is 70000 digits described by 784 features (28 x 28 pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we explore the shape of y we can also see that there are 70000 datapoints. This array contains the label or actual value for each item in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  9.,  9.,  9.])"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Split Features into (28x28 Matrix) \n",
    "\n",
    "We will next illustrate what each data point is when transformed to a 28x28 matrix. This is how images are represented to computers. Each image or row has 874 features because each image is 28x28. For the sake of illustration, I will pick a value at random from the dataset which is 53238. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_number = X[53238]\n",
    "test_number_image = test_number.reshape(28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is not so important but I will set pandas options to display max columns as 28 to avoid truncation of the data. I will also then import my previous transformation into a data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 28\n",
    "number_matrix = pd.DataFrame(test_number_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>112</td>\n",
       "      <td>229</td>\n",
       "      <td>229</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>162</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>230</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>249</td>\n",
       "      <td>222</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>242</td>\n",
       "      <td>137</td>\n",
       "      <td>138</td>\n",
       "      <td>188</td>\n",
       "      <td>196</td>\n",
       "      <td>246</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>219</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>120</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>185</td>\n",
       "      <td>255</td>\n",
       "      <td>254</td>\n",
       "      <td>144</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>245</td>\n",
       "      <td>172</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>253</td>\n",
       "      <td>232</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>226</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>244</td>\n",
       "      <td>165</td>\n",
       "      <td>149</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>219</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>214</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>237</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>235</td>\n",
       "      <td>253</td>\n",
       "      <td>236</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>242</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>234</td>\n",
       "      <td>88</td>\n",
       "      <td>71</td>\n",
       "      <td>234</td>\n",
       "      <td>253</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>234</td>\n",
       "      <td>254</td>\n",
       "      <td>236</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>225</td>\n",
       "      <td>254</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>249</td>\n",
       "      <td>253</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "      <td>253</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>232</td>\n",
       "      <td>253</td>\n",
       "      <td>244</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>245</td>\n",
       "      <td>253</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>155</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>153</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>232</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>206</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>247</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>240</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>247</td>\n",
       "      <td>196</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>177</td>\n",
       "      <td>160</td>\n",
       "      <td>254</td>\n",
       "      <td>236</td>\n",
       "      <td>160</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5   6    7    8    9    10   11   12   13   14   15  \\\n",
       "0    0   0   0   0   0   0   0    0    0    0    0    0    0    0    0    0   \n",
       "1    0   0   0   0   0   0   0    0    0    0    0    0    0    0    0    0   \n",
       "2    0   0   0   0   0   0   0    0    0    0    0    0    0    0    0    0   \n",
       "3    0   0   0   0   0   0   0    0    0    0    0    0    0    0    0    0   \n",
       "4    0   0   0   0   0   0   0    0    0    0    0    0    0    0    0    0   \n",
       "5    0   0   0   0   0   0   0    0   70   70  112  229  229  161  161  161   \n",
       "6    0   0   0   0   0   0  22  230  254  253  253  253  254  253  253  253   \n",
       "7    0   0   0   0   0   0  24  253  254  253  242  137  138  188  196  246   \n",
       "8    0   0   0   0   0   0  24  253  254  219   63    0    0    0    0   50   \n",
       "9    0   0   0   0   0   0   9  185  255  254  144   69    0    0    0    0   \n",
       "10   0   0   0   0   0   0   0   42  254  253  253  245  172   46    0    0   \n",
       "11   0   0   0   0   0   0   0    0  105  226  253  253  254  244  165  149   \n",
       "12   0   0   0   0   0   0   0    0    0   13  144  228  254  253  253  253   \n",
       "13   0   0   0   0   0   0   0    0    0    0    0    0   60  214  254  254   \n",
       "14   0   0   0   0   0   0   0    0    0    0    0    0  106  235  253  236   \n",
       "15   0   0   0   0   0   0   0    0    0    0    0  119  254  253  234   88   \n",
       "16   0   0   0   0   0   0   0    0    0    0   17  234  254  236   54    0   \n",
       "17   0   0   0   0   0   0   0    0    0    0  174  254  254   56    0    0   \n",
       "18   0   0   0   0   0   0   0    0    0  143  249  253  107    2    0    0   \n",
       "19   0   0   0   0   0   0   0    0    7  232  253  244   17    0    0    0   \n",
       "20   0   0   0   0   0   0   0    0   70  253  253   94    0    0    0    0   \n",
       "21   0   0   0   0   0   0   0    0   70  254  254  152    0    0    0   51   \n",
       "22   0   0   0   0   0   0   0    0    7  232  253  253  206  138  214  247   \n",
       "23   0   0   0   0   0   0   0    0    0  113  253  253  254  253  253  253   \n",
       "24   0   0   0   0   0   0   0    0    0   13  177  160  254  236  160  128   \n",
       "25   0   0   0   0   0   0   0    0    0    0    0    0    0    0    0    0   \n",
       "26   0   0   0   0   0   0   0    0    0    0    0    0    0    0    0    0   \n",
       "27   0   0   0   0   0   0   0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "     16   17   18   19   20  21  22  23  24  25  26  27  \n",
       "0     0    0    0    0    0   0   0   0   0   0   0   0  \n",
       "1     0    0    0    0    0   0   0   0   0   0   0   0  \n",
       "2     0    0    0    0    0   0   0   0   0   0   0   0  \n",
       "3     0    0    0    0    0   0   0   0   0   0   0   0  \n",
       "4     0    0    0    0    0   0   0   0   0   0   0   0  \n",
       "5   162   65    0    0    0   0   0   0   0   0   0   0  \n",
       "6   254  249  222  105    0   0   0   0   0   0   0   0  \n",
       "7   254  253  253  253  119   0   0   0   0   0   0   0  \n",
       "8   120  253  253  253  184   0   0   0   0   0   0   0  \n",
       "9    95  254  254  254  102   0   0   0   0   0   0   0  \n",
       "10  212  253  232   23    0   0   0   0   0   0   0   0  \n",
       "11  254  253  145    0    0   0   0   0   0   0   0   0  \n",
       "12  254  219   13    0    0   0   0   0   0   0   0   0  \n",
       "13  254  237   80    0    0   0   0   0   0   0   0   0  \n",
       "14  254  253  242   55    0   0   0   0   0   0   0   0  \n",
       "15   71  234  253  236    0   0   0   0   0   0   0   0  \n",
       "16    0   72  253  253   68   0   0   0   0   0   0   0  \n",
       "17    0   17  225  254  151   0   0   0   0   0   0   0  \n",
       "18    0    0  207  253  167   0   0   0   0   0   0   0  \n",
       "19    0   38  245  253   93   0   0   0   0   0   0   0  \n",
       "20   26  155  253  253   25   0   0   0   0   0   0   0  \n",
       "21  153  254  254  228    0   0   0   0   0   0   0   0  \n",
       "22  254  253  240   40    0   0   0   0   0   0   0   0  \n",
       "23  247  196   42    0    0   0   0   0   0   0   0   0  \n",
       "24   50    0    0    0    0   0   0   0   0   0   0   0  \n",
       "25    0    0    0    0    0   0   0   0   0   0   0   0  \n",
       "26    0    0    0    0    0   0   0   0   0   0   0   0  \n",
       "27    0    0    0    0    0   0   0   0   0   0   0   0  "
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can anyone guess what number this looks like? It looks like an 8 for me and its cool to visualize this in the way a computer views it. As you can see a higher pixel value (up to 255) indicates a more refined line while the edges have lower values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Visualize the Data in matplotlib\n",
    "\n",
    "Matplotlib is a common library for visualizations in python lets see what happens if we plot these arrays in plot form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noAg/ENT/ATL0tnCsY/B1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c337c8198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "plt.imshow(test_number_image, cmap = matplotlib.cm.binary,\n",
    "           interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see this is clearly an 8! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Confirm our hypothesis  \n",
    "Lets read the target variable of the specific row to see whether our guess was right. As we can see by validating through y[53238] the number is indeed an 8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[53238]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Data Pre-processing for Neural Networks \n",
    "\n",
    "Next, it is important to pre-process the input data for Keras. If the data is not preprocessed the neural network will not be able to process the data, create a model, and ultimately create predictions. The first step will be to separate the training data from the validation data. This is important in machine learning as the validation data functions as a separate dataset used to evaluate the models performance on unseen data. As we can see, the training data uses 60000 rows while the test/validation set uses 10000 rows. \n",
    "An illustration of this method called the holdout method can be seen below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TrainTest](http://www.nosimpler.me/wp-content/uploads/2016/08/training-test.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "y_test_backup = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will reshape the input variables as 28x28x1 for the neural network inputs. \n",
    "This is because there are 784 features (28x28) and 1 channel (gray scale photos)\n",
    "If the photo was an RGB this would be considered a 3 channel problem however MNIST deals with grayscale images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also important to reclass the variables as float 32 type as Keras commonly works with this type of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also if we devide the X_train and X_test by 255 we will get a value between 0 and 1 for each array. This is a process called normalization which wont be covered in this tutorial.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at X_train we can now see that it is of type float 32. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we must convert the class or y vectors to binary class arrays. This essentially means that we are converting the y values to be an array of 10 numbers. The number in the array that the y value is truly will receive a value of 1 while everything else will receive a value of 0.  \n",
    "\n",
    "An example of 5 below in the case of a binary class array: \n",
    "[0,0,0,0,1,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Build the Model\n",
    "\n",
    "The next block of code will build a sequential model via Keras. Although this tutorial will not go too into detail regarding the models specifications more documentation can be found at this link. I really recommend reading the official keras documentation as it is very informative. It is quite simple to start up a model code-wise!\n",
    "\n",
    "https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Build the Model Layers\n",
    "\n",
    "The add function can then be used to add layers to the CNN model and this part of the code focuses on building the various neural network layers. \n",
    "\n",
    "The dropout function helps prevent overfitting the training data. \n",
    "\n",
    "The softmax function ensures an output that is a probability distribution and that all values sum to 1. \n",
    "\n",
    "Although the below picture does not represent our neural network model it illustrates a what a basic CNN architecture would look like from input image all the way to output layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CNN](http://parse.ele.tue.nl/cluster/2/CNNArchitecture.jpg)\n",
    "Source: http://parse.ele.tue.nl/education/cluster2\n",
    "\n",
    "#### Our simple CNN architecture for this example can be defined as: \n",
    "\n",
    "* Input = 28 x 28 grayscale image \n",
    "\n",
    "\n",
    "* Convolutional layer with 32 feature maps of size 3×3.\n",
    "* Pooling layer taking the max over 2x2 patches.\n",
    "* Dropout layer with a probability of 25%.\n",
    "* Flatten layer.\n",
    "* Fully connected layer with 128 neurons and rectifier activation.\n",
    "* Output layer.\n",
    "\n",
    "\n",
    "* Output = Classification\n",
    "\n",
    "Although we wont cover in depth what all of these layers do they essentially work in conjunction to classify our image as a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Configure the Learning process\n",
    "In neural networks there are three functions that can be set that affect the learning process in Machine Learning.The compile functions exists to configure the learning process and includes the loss function, an optimizer, and the desired metric for evaluation. \n",
    "\n",
    "In this case: we have set the loss function to be categorical cross entrophy, the optimize as stochastic gradient descent, and an evaluation metric of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Fit the model to the data\n",
    "Next step is to fit the model to the data. The epochs is an argument that is usually specified by the user and means number of iterations on the entire dataset. For this case we have set 10 to train the model. Below you can see the how long each epoch takes, the loss, as well as the accuracy after each epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 31s 512us/step - loss: 0.5125 - acc: 0.8527\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 30s 499us/step - loss: 0.2551 - acc: 0.9234\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 31s 516us/step - loss: 0.1944 - acc: 0.9416\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 34s 559us/step - loss: 0.1578 - acc: 0.9525\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 35s 582us/step - loss: 0.1340 - acc: 0.9597\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 32s 535us/step - loss: 0.1178 - acc: 0.9643\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 30s 506us/step - loss: 0.1056 - acc: 0.9682\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 30s 498us/step - loss: 0.0968 - acc: 0.9696\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 31s 523us/step - loss: 0.0897 - acc: 0.9721\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 31s 510us/step - loss: 0.0817 - acc: 0.9738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c2789e588>"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 15: Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important steps is to evaluate the data. We performed our original experiments with the training data but now we will evaluate the model on the untouched/unseen test data. \n",
    "The below code calculates loss and accuracy scores for the above model. \n",
    ".07 loss and 97 % accuracy. Not so bad if I may say so myself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 245us/step\n",
      "[0.075426249891519553, 0.97550000000000003]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 16: View Predictions Vs Actual Values (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also often like to input my predictions and actual values in a dataframe so I can see which values were incorrectly classified. This is optional but can be helpful when you are trying to understand your classifiers performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual  Predictions\n",
       "1     0.0            0\n",
       "2     0.0            0\n",
       "3     0.0            0\n",
       "4     0.0            0\n",
       "5     0.0            0\n",
       "6     0.0            0\n",
       "7     0.0            0\n",
       "8     0.0            0\n",
       "9     0.0            0"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test)\n",
    "x = list(predictions)\n",
    "y = list(y_test_backup)\n",
    "results = pd.DataFrame({'Actual': y, 'Predictions': x})\n",
    "results[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations !!!\n",
    "\n",
    "Good job on building your first CNN model and I hope this was a good introduction to the world of computer vision and machine learning. This tutorial only glanced over many aspects of Convolutional Neural Networks but hopefully this tutorial has sparked your interest to learn more and become a part of the machine learning revolution. \n",
    "\n",
    "Through this tutorial you should have learned the basics of: \n",
    "* Computer Vision \n",
    "* MNIST Dataset \n",
    "* Neural Networks and CNN's (Convolutional Neural Networks) \n",
    "* Keras \n",
    "* How to implement a CNN model in Jupyter Notebook/Python\n",
    "\n",
    "For further reference, I recommend reading the official Keras documentation, participating in kaggle/deep analytics challenges and modifying the model parameters, as well as reading recent research related to CNN's and neural networks. \n",
    "\n",
    "\n",
    "Additional Resources: \n",
    "\n",
    "\n",
    "MNIST Direct Link - http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "\n",
    "Keras Documentation- https://keras.io/ja/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
